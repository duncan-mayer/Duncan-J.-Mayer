[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Duncan J. Mayer",
    "section": "",
    "text": "bayesian inference\n\n\nsimulation\n\n\nbase\n\n\nr\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2022\n\n\nDuncan J. Mayer\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\npublications\n\n\npdf\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2022\n\n\nDuncan J. Mayer\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nWelcome\n\n\n\n\n\n\n\n\n\n\n\nOct 15, 2022\n\n\nDuncan J. Mayer\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/publications/index.html",
    "href": "posts/publications/index.html",
    "title": "Publications",
    "section": "",
    "text": "Here is a list of my publications and select presentations, with links to PDFs. I will updated it periodically."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Starting a Quarto Blog",
    "section": "",
    "text": "This blog is my transition to quarto, and a place I’ll write about topics that interest me, or things I’m learning. Check out the my about page to learn more about me.\nSome items and topics that may appear on this blog include descriptions of presentations I make, or publications I contribute to. I may also write about spatial statistics, nonlinearity, and select topics in statistical inference.\nAdditionally, I’d like to use this blog to practice programming in a more public space. I have nearly a decade of experience with R, but I’d like to improve with python, and explore popular workflows in R that I haven’t yet. So, some posts related to those topics may appear here as well.\n\n\n\nGlasgow Scotland, 1955"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a statistician at BeVera Solutions and a PhD candidate with the Center on Poverty and Community Development in the Jack Joesph, and Morton Mandel School of Applied Social Sciences at Case Western Reserve University"
  },
  {
    "objectID": "posts/publications/index.html#publications",
    "href": "posts/publications/index.html#publications",
    "title": "Publications",
    "section": "Publications",
    "text": "Publications\nMayer, D. J., Groza, V. (in press) Promoting Children’s Rights in Program Evaluation. American Journal of Evaluation.\nMayer, D. J. (2022) Simmer Down Now! A Study of Revenue Volatility and Dissolution in Nonprofit Organizations. Nonprofit and Voluntary Sector Quarterly. https://doi.org/10.1177/08997640221126147 pdf\nMayer, D. J., Fischer, R. L. (2022) Can a Measurement Error Perspective Improve Estimation in Neighborhood Effects Research? A Hierarchical Bayesian Methodology. Social Science Quarterly. https://doi.org/10.1111/ssqu.13190 pdf"
  },
  {
    "objectID": "posts/publications/index.html#select-presentations",
    "href": "posts/publications/index.html#select-presentations",
    "title": "Publications",
    "section": "Select Presentations",
    "text": "Select Presentations\nMayer, D. J. (2022). Understanding the Geography of Cuyahoga County’s Nonprofit Sector Through Form-990 Data. Data Days Cleveland. slides"
  },
  {
    "objectID": "posts/Easy Inference with Informal Bayes/index.html",
    "href": "posts/Easy Inference with Informal Bayes/index.html",
    "title": "Easy Inference with Informal Bayes",
    "section": "",
    "text": "A Simple Application\nHaving built a function to sample the posterior of regression parameters, lets see how this would play out in practice. Consider the following simplified situation where we have two important variables representing factors that exist simultaneously. For example, these may be the amount of resources allocated to two departments, or two types of amenities you offer patrons. The simultaneously deployment is important for the ceteris paribus interpretation, as well as for the setup, otherwise the model could be constructed as a choice between two options. So, say we wish to know which amenity to build out further, or which department to would benefit the company more if given additional resources. It’s a slightly unconventional question, and staring at the estimates of a linear model won’t give you any insight as the results aren’t calibrated for such a comparison. Rather, to prepare for such an analysis, we might take the approach of an informal power analysis to estimate the required sample (e.g., number of locations, employees, or whatever the unit happens to be).\nThe following function takes a vector (bx, the fixed, but unknown conditional mean parameters), a variance-covariance matrix (sigma), a constant (const), as well as number of samples (n), and produces a linear model from the results. In the example I’ve kept it to three covariates including our two focal variables, without loss of generality.\n\n\nCode\nsimple_sim <- function(n = 1e3, bx = c(2,6,4), const = 5,\n                       mu = c(10, 3, 4), \n                       sigma = matrix(\n                               data = c(1.11, 0.66, -0.54,  \n                                        0.66,  0.84,  0.43, \n                                        -0.54,  0.43,  2.00), nrow = 3)\n                       ) {\n  # check mu and sigma\n  if (length(mu) != dim(sigma)[1]) {stop(\"mu and sigma are noncomforable\")}\n  if (!is.matrix(sigma) | (nrow(sigma) == ncol(sigma)) == FALSE) {stop(\"sigma either not a matrix or not a square matrix\")}\n  # create data\n  dft <- MASS::mvrnorm(n, mu = mu, Sigma = sigma)\n  yy <- as.vector(rnorm(n, const, const) + dft %*% bx + rnorm(n))\n  dft <- as.data.frame(dft)\n  names(dft) <- letters[1:length(names(dft))]\n  names(dft)[1:2] <- c(\"x1\", \"z1\")\n  dft <- cbind(yy, dft)\n  # fit model\n  lmt <- lm(yy ~ ., data = dft)\n  return(lmt)\n}\n\n\nNext, I generate some candidate sample sizes, ranging from 100 to 1000, incremented by 100. Typically, smaller samples are less resource intensive, so I’d like as small a sample as possible without sacrificing the precision of the estimated difference. Then, I apply the function to sample the posterior, the first five rows of which are shown below, where the samples column represents the sample size used in them model.\n\n\nCode\nset.seed(89)\nn_rep <- seq(0,1e3, by = 100)[-1]\nout <- list()\n for (i in seq_along(n_rep) ) {\n    out[[i]] <- simple_sim(n = n_rep[[i]])\n }\ndfout <- lapply(out, infbayes)\nfor (i in seq_along(dfout)) {\n  dfout[[i]]$samples <- n_rep[[i]]\n}\ndfout <- do.call(rbind.data.frame, dfout)\nhead(dfout,5)\n\n\n  (Intercept)       x1       z1        c samples\n1   -37.27578 6.713368 1.169126 6.607417     100\n2   -22.99647 5.028081 3.205434 5.264976     100\n3   -37.89262 6.541961 1.999250 6.241230     100\n4   -14.29463 3.982110 4.065508 5.451617     100\n5   -29.11941 6.038991 1.042586 5.972961     100\n\n\nHaving conducted informal Bayes, the results can be easily plotted, as in the figure below. The figure gives us a feel for the implications of the sample size for the difference in conditional mean parameters in a linear model. The results show that, under the assumptions of the model and a difference of 4 with no heterogeneity, you’d probably want a sample of at least 700. If those assumptions aren’t reasonable, or you need additional covariates, then you can adjust the simulation.\n\n\nCode\nlibrary(ggplot2)\ndfout$tdiff <- dfout$z1 - dfout$x1\n\nggplot(data = dfout, aes(tdiff)) + geom_histogram(binwidth = .01, fill = \"black\") +\n  facet_wrap(~ samples, nrow = 2) + labs(x = \"Difference\", y = \"Frequency\") +\n            theme_bw() +\n              theme(legend.position = \"none\", text=element_text(family=\"Times New Roman\", face=\"bold\", size=12))\n\n\n\n\n\n\n\nReferences\nGelman, A., & Hill, J. (2006). Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge University Press; Cambridge Core. https://doi.org/10.1017/CBO9780511790942\nKing, G., Tomz, M., & Wittenberg, J. (2000). Making the Most of Statistical Analyses: Improving Interpretation and Presentation. American Journal of Political Science, 44(2), 15.\n\n\n\n\n\nFootnotes\n\n\nWhy multivariate normal? A general justification often relies on the central limit theorem under finite variance, in this example using OLS, the sampling distribution of the conditional mean parameters are known to be marginally normal and jointly multivariate normal with variance-covariance equal to \\(\\sigma^2 (X'X)^{-1}\\)↩︎"
  }
]